{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Liabraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yi.chen\\GitHub\\training_prework_titanic\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm, grid_search, datasets\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "project_path = \"%s\" % os.getcwd()\n",
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== train dataset :\n",
      "(891, 12)\n",
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked']\n",
      "====== test dataset :\n",
      "(418, 11)\n",
      "['PassengerId' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare'\n",
      " 'Cabin' 'Embarked']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1309, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"%s/data/train.csv\" % project_path, sep=\",\")\n",
    "test = pd.read_csv(\"%s/data/test.csv\" % project_path, sep=\",\")\n",
    "print \"====== train dataset :\"\n",
    "print train.shape\n",
    "print train.columns.values\n",
    "print \"====== test dataset :\"\n",
    "print test.shape\n",
    "print test.columns.values\n",
    "\n",
    "# create Survived column for test dataset\n",
    "test['Survived'] = 0\n",
    "data = pd.concat([train, test], ignore_index=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Create new feature - Salutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr        757\n",
       "Miss      260\n",
       "Mrs       197\n",
       "Master     61\n",
       "Dr          8\n",
       "Rev         8\n",
       "Sir         5\n",
       "Col         4\n",
       "Lady        4\n",
       "Ms          2\n",
       "Mlle        2\n",
       "Mme         1\n",
       "Name: Salutation, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Salutation'] = data.apply(lambda row: row.Name.split(',')[1].split('.')[0].strip(), axis=1)\n",
    "data.Salutation.value_counts(dropna=False)\n",
    "\n",
    "# group certain usual titles\n",
    "data.loc[data.Salutation.isin(['Dona', 'the Countess', 'Jonkheer']), 'Salutation'] = 'Lady'\n",
    "data.loc[data.Salutation.isin(['Capt', 'Don', 'Major']), 'Salutation'] = 'Sir'\n",
    "\n",
    "data.Salutation.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new feature - Surname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Small         903\n",
       "Andersson      11\n",
       "Sage           11\n",
       "Goodwin         8\n",
       "Asplund         8\n",
       "Davies          7\n",
       "Skoog           6\n",
       "Fortune         6\n",
       "Rice            6\n",
       "Brown           6\n",
       "Ford            6\n",
       "Panula          6\n",
       "Johnson         6\n",
       "Carter          6\n",
       "Smith           6\n",
       "Palsson         5\n",
       "Lefebre         5\n",
       "Ryerson         5\n",
       "Williams        5\n",
       "Kelly           5\n",
       "Thomas          5\n",
       "Goldsmith       4\n",
       "Herman          4\n",
       "Hocking         4\n",
       "Baclini         4\n",
       "Olsen           4\n",
       "Johansson       4\n",
       "Dean            4\n",
       "West            4\n",
       "Hart            4\n",
       "             ... \n",
       "Hays            3\n",
       "Cor             3\n",
       "Sandstrom       3\n",
       "Compton         3\n",
       "Chapman         3\n",
       "Keane           3\n",
       "Peacock         3\n",
       "Navratil        3\n",
       "Moran           3\n",
       "Thayer          3\n",
       "Newell          3\n",
       "Collyer         3\n",
       "Frauenthal      3\n",
       "Jensen          3\n",
       "Spedden         3\n",
       "Widener         3\n",
       "Oreskovic       3\n",
       "Karlsson        3\n",
       "Crosby          3\n",
       "O'Brien         3\n",
       "Hickman         3\n",
       "Moubarek        3\n",
       "Peter           3\n",
       "Touma           3\n",
       "Danbom          3\n",
       "Caldwell        3\n",
       "Douglas         3\n",
       "Van Impe        3\n",
       "Quick           3\n",
       "Rosblom         3\n",
       "Name: Surname, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Surname'] = data.apply(lambda row: row.Name.split(',')[0].strip(), axis=1)\n",
    "counts = data['Surname'].value_counts(dropna=False)\n",
    "\n",
    "# set surname to a tag 'small' for those whose occurence is less than 3\n",
    "surname_small_list = counts[counts <= 2].index.tolist()\n",
    "data.loc[data.Surname.isin(surname_small_list), 'Surname'] = 'Small'\n",
    "data['Surname'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill missing values in column Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the mean of age\n",
    "age_mean = data.Age.mean()\n",
    "# fill missing ages by the mean\n",
    "data.loc[data.Age.isnull(), 'Age'] = age_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new feature - AgeRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "middle    974\n",
       "young     225\n",
       "aged      110\n",
       "Name: AgeRange, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_age_range(age):\n",
    "    if age < 20:\n",
    "        return 'young'\n",
    "    elif age < 50:\n",
    "        return 'middle'\n",
    "    elif age >= 50:\n",
    "        return 'aged'\n",
    "    else:\n",
    "        return age\n",
    "    \n",
    "data['AgeRange'] = data.apply(lambda row: get_age_range(row.Age), axis=1)\n",
    "data.AgeRange.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new feature - FamilySize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     790\n",
       "1     235\n",
       "2     159\n",
       "3      43\n",
       "5      25\n",
       "4      22\n",
       "6      16\n",
       "10     11\n",
       "7       8\n",
       "Name: FamilySize, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['FamilySize'] = data['SibSp'] + data['Parch']\n",
    "data.FamilySize.value_counts(dropna=False)\n",
    "\n",
    "# for those whose family size is less than 3, set the tag 'Small'\n",
    "#data.loc[data.FamilySize <=2, 'FamilySize'] = 'Small'\n",
    "#data.FamilySize.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new feature - TicketCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Digital    957\n",
       "PC          92\n",
       "C.A.        69\n",
       "S.C.        30\n",
       "A.5.        29\n",
       "SOTON/O     27\n",
       "STON/O      22\n",
       "S.O.        16\n",
       "W.C.        15\n",
       "A.4.        10\n",
       "F.C.C.       9\n",
       "C            8\n",
       "PP           4\n",
       "W.E.P.       4\n",
       "LINE         4\n",
       "F.C.         3\n",
       "P/PP         2\n",
       "A.Q.         2\n",
       "S.W.         2\n",
       "LP           1\n",
       "A.           1\n",
       "Fa           1\n",
       "S.P.         1\n",
       "Name: TicketCategory, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ticket_category(ticket):\n",
    "    if ticket.isdigit(): # contain only digital numbers\n",
    "        return 'Digital'\n",
    "    elif ticket.isalpha(): # contain only letters\n",
    "        return ticket\n",
    "    else:\n",
    "        return ticket.split()[0]\n",
    "\n",
    "data['TicketCategory'] = data.apply(lambda row: get_ticket_category(row.Ticket), axis=1)\n",
    "#print data.TicketCategory.value_counts(dropna=False)\n",
    "\n",
    "# replace certain similar letters by a base one\n",
    "data = data.replace({\n",
    "    'TicketCategory': {\n",
    "            'A./5.' : 'A.5.',\n",
    "            'A.5' : 'A.5.',\n",
    "            'A/5' : 'A.5.',\n",
    "            'A/5.' : 'A.5.',\n",
    "            'A/S' : 'A.5.',\n",
    "            'A/4' : 'A.4.',\n",
    "            'A/4.' : 'A.4.',\n",
    "            'A4.' : 'A.4.',\n",
    "            'AQ/4': 'A.Q.',\n",
    "            'AQ/3.': 'A.Q.',\n",
    "            'C.A./SOTON' : 'C.A.',\n",
    "            'CA' : 'C.A.',\n",
    "            'CA.' : 'C.A.',\n",
    "            'C.A./SOTON' : 'C.A.',\n",
    "            'S.C./A.4.': 'S.C.',\n",
    "            'S.C./PARIS': 'S.C.',\n",
    "            'S.O./P.P.': 'S.O.',\n",
    "            'S.O.C.': 'S.O.',\n",
    "            'S.O.P.': 'S.O.',\n",
    "            'SO/C': 'S.O.',\n",
    "            'SC': 'S.C.',\n",
    "            'SC/AH': 'S.C.',\n",
    "            'SC/AH': 'S.C.',\n",
    "            'SC/PARIS': 'S.C.',\n",
    "            'SC/Paris': 'S.C.',\n",
    "            'SC/A4': 'S.C.',\n",
    "            'SC/A.3': 'S.C.',\n",
    "            'SCO/W': 'S.C.',\n",
    "            'SOTON/O.Q.': 'SOTON/O',\n",
    "            'SOTON/O2': 'SOTON/O',\n",
    "            'SOTON/OQ': 'SOTON/O',\n",
    "            'STON/O2.': 'STON/O',\n",
    "            'STON/OQ.': 'STON/O',\n",
    "            'S.W./PP': 'S.W.',\n",
    "            'SW/PP': 'S.W.',\n",
    "            'W./C.' : 'W.C.',\n",
    "            'W/C' : 'W.C.',\n",
    "            'WE/P' : 'W.E.P.',\n",
    "    }\n",
    "})\n",
    "\n",
    "data.TicketCategory.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new feature - TicketFirstLetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    957\n",
       "S     98\n",
       "P     98\n",
       "C     77\n",
       "A     42\n",
       "W     19\n",
       "F     13\n",
       "L      5\n",
       "Name: TicketFirstLetter, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TicketFirstLetter'] = data.apply(lambda row: row.TicketCategory[0], axis=1)\n",
    "data.TicketFirstLetter.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new feature - TicketNumberLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    606\n",
       "5    377\n",
       "4    245\n",
       "7     46\n",
       "2     15\n",
       "3     12\n",
       "1      4\n",
       "0      4\n",
       "Name: TicketNumberLength, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ticket_number_length(ticket):\n",
    "    if ticket.isdigit(): # contain only digital numbers\n",
    "        return len(ticket)\n",
    "    elif ticket.isalpha(): # contain only letters\n",
    "        return 0\n",
    "    else:\n",
    "        return len(ticket.split()[1])\n",
    "    \n",
    "data['TicketNumberLength'] = data.apply(lambda row: get_ticket_number_length(row.Ticket), axis=1)\n",
    "data.TicketNumberLength.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill missing values in Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[data.Fare.isnull(), 'Fare'] = np.mean(data['Fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new feature - FareLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0-8)      360\n",
       "[8-16)     354\n",
       "32+        312\n",
       "[16-32)    283\n",
       "Name: FareLevel, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_fare_level(fare):\n",
    "    if fare < 8:\n",
    "        return '[0-8)'\n",
    "    elif fare < 16:\n",
    "        return '[8-16)'\n",
    "    elif fare < 32:\n",
    "        return '[16-32)'\n",
    "    else:\n",
    "        return '32+'\n",
    "\n",
    "data['FareLevel'] =  data.apply(lambda row: get_fare_level(row.Fare), axis=1)\n",
    "data.FareLevel.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new feature - CabinCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    1014\n",
       "C      94\n",
       "B      65\n",
       "D      46\n",
       "E      41\n",
       "A      22\n",
       "F      21\n",
       "G       5\n",
       "T       1\n",
       "Name: CabinCategory, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_letters(s):\n",
    "    \n",
    "    try:\n",
    "        match = re.search('[A-Z]+', s)\n",
    "        if match:\n",
    "            return match.group()\n",
    "        else:\n",
    "            return s\n",
    "    except Exception as e:\n",
    "        return 'N'\n",
    "\n",
    "data['CabinCategory'] = data.apply(lambda row: get_letters(row.Cabin), axis=1)\n",
    "data.CabinCategory.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill missing values in column Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[data.Cabin.isnull(), 'Cabin'] = 'N'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform labels data to numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data_transformed = data.copy()\n",
    "\n",
    "# Cabin\n",
    "data_transformed['Cabin'] = le.fit_transform(data_transformed['Cabin'])\n",
    "# Embarked\n",
    "data_transformed['Embarked'] = le.fit_transform(data_transformed['Embarked'])\n",
    "# Name\n",
    "data_transformed['Name'] = le.fit_transform(data_transformed['Name'])\n",
    "# Sex\n",
    "data_transformed['Sex'] = le.fit_transform(data_transformed['Sex'])\n",
    "# Ticket\n",
    "data_transformed['Ticket'] = le.fit_transform(data_transformed['Ticket'])\n",
    "# Salutation\n",
    "data_transformed['Salutation'] = le.fit_transform(data_transformed['Salutation'])\n",
    "# Surname\n",
    "data_transformed['Surname'] = le.fit_transform(data_transformed['Surname'])\n",
    "# AgeRange\n",
    "data_transformed['AgeRange'] = le.fit_transform(data_transformed['AgeRange'])\n",
    "# TicketCategory\n",
    "data_transformed['TicketCategory'] = le.fit_transform(data_transformed['TicketCategory'])\n",
    "# TicketFirstLetter\n",
    "data_transformed['TicketFirstLetter'] = le.fit_transform(data_transformed['TicketFirstLetter'])\n",
    "# FareLevel\n",
    "data_transformed['FareLevel'] = le.fit_transform(data_transformed['FareLevel'])\n",
    "# CabinCategory\n",
    "data_transformed['CabinCategory'] = le.fit_transform(data_transformed['CabinCategory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train & test data from train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get train data\n",
    "train_data = data_transformed.head(len(train))\n",
    "\n",
    "# split features and target\n",
    "features_list = train_data.columns.values.tolist()\n",
    "features_list.remove('Survived')\n",
    "features_list.remove('PassengerId')\n",
    "features = train_data[features_list]\n",
    "labels = train_data['Survived']\n",
    "\n",
    "# split train and test data\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try classification models on train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores - Accuracy: 0.81111, Precision: 0.86111, Recall: 0.72093\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "# compute scores\n",
    "acc = accuracy_score(pred, labels_test)\n",
    "precision = precision_score(pred, labels_test)\n",
    "recall = recall_score(pred, labels_test)\n",
    "print \"Scores - Accuracy: %.5f, Precision: %.5f, Recall: %.5f\" % (acc, precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get test data\n",
    "test_data = data_transformed.tail(len(test))\n",
    "features_test = test_data[features_list]\n",
    "\n",
    "# predict the test data\n",
    "pred = clf.predict(features_test)\n",
    "passenger_id = np.arange(len(train) + 1, len(data_transformed) + 1).tolist()\n",
    "\n",
    "# construct result data and write to csv\n",
    "result = pd.DataFrame({'PassengerId' : passenger_id, 'Survived' : pred})\n",
    "result.to_csv(\"%s/data/prediction.csv\" % project_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
